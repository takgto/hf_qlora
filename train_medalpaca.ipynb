{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa99044-c835-4879-8b7b-ff50aed72fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t_goto/hf_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'/home/t_goto/hf_env/lib/python3.10/site-packages') # if use virtual environment, add the path of the environment\n",
    "import torch\n",
    "import datasets\n",
    "from datasets import load_from_disk\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from utils import InstructDataset, InstructCollator\n",
    "from huggingface_hub import login\n",
    "token = os.getenv('HF_TOKEN')\n",
    "login(token)\n",
    "load_data_flag = False # True if training data is reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52038c44-e89a-453b-b43a-01530323f927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just confirmation, CUDA_VISIBLE_DEVISES shold be only one.\n",
    "os.environ.get('CUDA_VISIBLE_DEVICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b7e4486-624b-4d5b-9e69-14125219a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"bfloat16\")\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    #llm_int8_threshold=200.0,\n",
    "    #load_in_8bit=True,\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    #bnb_8bit_use_double_quant=False, # need to avoid cast issue.\n",
    "    #bnb_8bit_quant_type=\"nf8\",\n",
    "    #bnb_8bit_compute_dtype=compute_dtype,\n",
    "    #llm_int8_skip_modules= ['decoder', 'lm_head', 'wo'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db66cd1e-9cf8-4065-860a-33b45b655391",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|█████████████████████████████████████████████████████████████████████████████| 4/4 [08:49<00:00, 132.37s/it]\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"jetmoe/jetmoe-8b\"\n",
    "#model_name = \"NousResearch/llama-2-7b-chat-hf\"\n",
    "#model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "#model_name = \"microsoft/phi-1_5\"\n",
    "#model_name = \"h2oai/h2o-danube2-1.8b-chat\"\n",
    "#model_name = \"Aratako/Qwen1.5-MoE-2x7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #device_map=\"auto\",\n",
    "    device_map = {\"\": torch.cuda.current_device()},\n",
    "    quantization_config=quant_config\n",
    "    # torch_dtype=torch.float16, # この時点でtorch.float16を指定すると、train時のlossが0.0になって学習がうまくいかない。原因がよくわかっていません。\n",
    ")\n",
    "model.config.use_cache = False # added in jetmoe\n",
    "model.config.pretraining_tp = 1 # added in jetmoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea57ed4b-85e3-484c-a266-ef87c0d103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████| 653/653 [00:00<00:00, 4.64MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 15.8M/15.8M [00:01<00:00, 12.2MB/s]\n",
      "Generating train split: 100%|██████████████████████████████████████████████████████████| 2208/2208 [00:00<00:00, 11762.45 examples/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 2208/2208 [00:16<00:00, 135.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data1=datasets.load_dataset(\"medalpaca/medical_meadow_mediqa\")\n",
    "train_dataset1 = InstructDataset((list(med_data1['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15f337f-05b4-4926-b62c-aa5b9daf0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 1.59M/1.59M [00:00<00:00, 4.39MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████| 3787/3787 [00:00<00:00, 139957.96 examples/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 3787/3787 [00:03<00:00, 1123.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data2=datasets.load_dataset(\"medalpaca/medical_meadow_mmmlu\")\n",
    "train_dataset2 = InstructDataset((list(med_data2['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ebfe97-d1c9-4e12-9c14-90c358da7bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████| 1.40k/1.40k [00:00<00:00, 7.37MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 3.49M/3.49M [00:00<00:00, 6.08MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████| 5942/5942 [00:00<00:00, 113431.28 examples/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 5942/5942 [00:04<00:00, 1219.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5942"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data3=datasets.load_dataset(\"medalpaca/medical_meadow_wikidoc_patient_information\")\n",
    "train_dataset3 = InstructDataset((list(med_data3['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b6ceb7-342d-48d0-9aec-05b7371340f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████████| 920/920 [00:00<00:00, 6.12MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████████████████████| 936k/936k [00:01<00:00, 931kB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████| 2446/2446 [00:00<00:00, 167208.87 examples/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 2446/2446 [00:01<00:00, 1225.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2446"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data4=datasets.load_dataset(\"medalpaca/medical_meadow_pubmed_causal\")\n",
    "train_dataset4 = InstructDataset((list(med_data4['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a107acf2-d083-4736-96a4-fa78320f5f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████| 1.04k/1.04k [00:00<00:00, 6.37MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 2.51M/2.51M [00:00<00:00, 7.01MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████████████████████████| 8676/8676 [00:00<00:00, 222044.61 examples/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 8676/8676 [00:06<00:00, 1293.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8676"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data5=datasets.load_dataset(\"medalpaca/medical_meadow_health_advice\")\n",
    "train_dataset5 = InstructDataset((list(med_data5['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e789e662-c1f5-4c18-9be8-da9df70232b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████| 1.24k/1.24k [00:00<00:00, 7.36MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 17.7M/17.7M [00:00<00:00, 24.2MB/s]\n",
      "Generating train split: 100%|███████████████████████████████████████████████████████| 33955/33955 [00:00<00:00, 133862.70 examples/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 33955/33955 [00:28<00:00, 1212.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33955"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data6=datasets.load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\n",
    "train_dataset6 = InstructDataset((list(med_data6['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "912dfca8-fbc0-48ab-adb1-b3be3d7ab275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|███████████████████████████████████████████████████████████████████████| 1.41k/1.41k [00:00<00:00, 8.78MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████| 10.6M/10.6M [00:00<00:00, 16.0MB/s]\n",
      "Generating train split: 100%|████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 58653.88 examples/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:12<00:00, 810.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_data7=datasets.load_dataset(\"medalpaca/medical_meadow_wikidoc\")\n",
    "train_dataset7 = InstructDataset((list(med_data7['train'])), tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "len(train_dataset7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e86454-f3d1-44d7-8f5d-8db493000836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 8142/8142 [00:15<00:00, 516.62it/s]\n"
     ]
    }
   ],
   "source": [
    "med_data = load_from_disk(\"meadow_train\")\n",
    "train_dataset = InstructDataset(med_data, tokenizer, ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a460adf-8310-436f-88d8-5cb71426aecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8142"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(med_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be15fbf-2055-435b-8832-1a2c35fcc44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75156"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "med_datasets = ConcatDataset([train_dataset1,train_dataset2,train_dataset3,train_dataset4,train_dataset5,train_dataset6,train_dataset7,train_dataset])\n",
    "len(med_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "277919d2-b3e5-4b4b-86de-e2f09791e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "collator = InstructCollator(tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(med_datasets, collate_fn=collator, batch_size=4, shuffle=True)\n",
    "#batch = next(iter(train_loader)) # for checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccdb76df-fdff-4f47-abdc-71add87bf471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "332fc146-eba4-43f7-b267-b7a2300ac7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    #target_modules=['kv_proj', 'layer'] # need this only for jetmoe-8b\n",
    "    target_modules=['kv_proj'] # need this only for jetmoe-8b\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c271f8bf-0400-4286-8fbe-588db193269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = TrainingArguments(\n",
    "    output_dir=\"./results_jetmoe-8b-4bit\",\n",
    "    #output_dir=\"./results_llama2-7b-more_max\",\n",
    "    #output_dir=\"./results_tiny_llama-1.1b\",\n",
    "    #output_dir=\"./results_phi-1_5\",\n",
    "    #output_dir=\"./results_jetmoe_more_max\",\n",
    "    #num_train_epochs=0.2, # epoch 3758 too long\n",
    "    num_train_epochs=0.05, # epoch 940, \n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    #report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6459951f-bd1d-41f5-87df-2db02ced4639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t_goto/hf_env/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:246: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "collator = InstructCollator(tokenizer, ignore_index=tokenizer.pad_token_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=med_datasets,\n",
    "    data_collator=collator,\n",
    "    peft_config=peft_params,\n",
    "    max_seq_length=None,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    "    packing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c11b2246-78a3-4204-9945-113a1d001b74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='940' max='940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [940/940 17:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>4.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.266200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.229600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.621900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.584500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.510900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.161600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.248600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.552100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.602600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.528700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.511700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.195800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.559900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.247900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.207100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.509300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1063.4493739623576 [sec]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t_goto/hf_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "trainer.train()\n",
    "end = time.perf_counter()\n",
    "print(f'{end-start} [sec]')\n",
    "trainer.model.save_pretrained(\"llama2_FT_train_adapter1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
